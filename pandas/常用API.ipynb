{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitpython36conda887ba476e9aa484bad06fe49784f25a0",
   "display_name": "Python 3.6.9 64-bit ('python36': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   a  b  c\n0  1  2  3\n1  2  1  3\n2  2  1  1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>a</th>\n      <th>b</th>\n      <th>c</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# 合并Series成DataFrame\n",
    "\n",
    "a = pd.Series({'a':1, 'b':2, 'c':3})\n",
    "b = pd.Series({'b':1, 'a':2, 'c':3})\n",
    "c = pd.Series({'a':2, 'b':1, 'c':1})\n",
    "pd.DataFrame([a,b,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取列\n",
    "\n",
    "a = pd.DataFrame({'a':[1,2,3,4], 'b':[5,6,7,8]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计各个标签的数量\n",
    "\n",
    "train_df['情感倾向'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集的基本预览\n",
    "\n",
    "# 直接打印表对象\n",
    "df\n",
    "\n",
    "# 可以得到属性类别情况\n",
    "df.info()\n",
    "\n",
    "# 查看每列的类型\n",
    "df.dtypes\n",
    " \n",
    "# 查找多列，列索引必须要用中括号扩起来\n",
    "complaints[['Complaint Type', 'Borough']][:10]\n",
    " \n",
    "# 查找多行，这里的ix索引标签函数必须是中括号[]\n",
    "student.ix[[0,2,4,5,7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#条件查询\n",
    "\n",
    "# 查询出所有12岁以上的女生姓名、身高和体重\n",
    "student[(student['Sex']=='F') & (student['Age']>12)][['Name','Height','Weight']]\n",
    " \n",
    "# 查看某列中各个种类出现的次数\n",
    "complaints['Complaint Type'].value_counts()\n",
    " \n",
    "# 查看某列中属于某个种类的数据\n",
    "# 为了得到噪音投诉，我们需要找到 Complaint Type  列为 Noise -Street/Sidewalk  的行。 我会告诉你如何做，然后解释发生了什么。\n",
    "noise_complaints = complaints[complaints['Complaint Type'] == \"Noise - Street/Sidewalk\"]\n",
    " \n",
    "# 将多个条件与 & 运算符组合\n",
    "is_noise = complaints['Complaint Type'] == \"Noise - Street/Sidewalk\"\n",
    "in_brooklyn = complaints['Borough'] == \"BROOKLYN\"\n",
    "complaints[is_noise & in_brooklyn][:5]\n",
    "\n",
    "# 函数中用来判断条件符合的数据集并返回\n",
    "# df.query(条件式) \n",
    "df_new.query(\"duration > 100 & index == 'UK'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保留指定标签范围内的数据\n",
    "\n",
    "train_df[train_df['情感倾向'].isin(['0','1','-1'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日期的处理\n",
    "\n",
    "train_df['time'] = pd.to_datetime('2020年' + train_df['微博发布时间'], format='%Y年%m月%d日 %H:%M', errors='ignore')\n",
    "train_df['month'] =  train_df['time'].dt.month\n",
    "train_df['day'] =  train_df['time'].dt.day\n",
    "train_df['dayfromzero']  = (train_df['month']-1)*31 +  train_df['day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 排序sort()\n",
    "\n",
    "# 将一列排序\n",
    "Table[['某列']].sort()\n",
    " \n",
    "# 将多列按照某一列排序\n",
    "Table[['列1', '列2', '列3']].sort('列1')\n",
    " \n",
    "# 值排序一般使用sort_values()\n",
    "Table.sort_values(by = ['sex', 'age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抽样take()\n",
    "\n",
    "# 对于一个dataframe，take函数可以根据sampler按照行索引抽取数据\n",
    "df.take(sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 哑变量get_dummies()\n",
    "\n",
    "pd.get_dummies(df['key']，prefix='key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 缺失值\n",
    "\n",
    "df.dropna()\n",
    "\n",
    "df.fillna()\n",
    "\n",
    "df.isnull()   df.isna()  #isnull是isna的别名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分组\n",
    "\n",
    "grp1=df1.groupby('symbol')\n",
    "\n",
    "#根据两列数据将数据分组\n",
    "grp2=df1.groupby(['symbol','tdate'])\n",
    "\n",
    "#通过组名访问 组名对应的数据\n",
    "print(grp1.get_group('001'))\n",
    "print(grp2.get_group(('001','201901')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 表连接\n",
    "\n",
    "# merge()函数\n",
    "\n",
    "# 1.默认情况下，merge函数实现的是两个表之间的内连接，即返回两张表中共同部分的数据。\n",
    "# 2.可以通过how参数设置连接的方式，inner或空为内连接，left为左连接；right为右连接；outer为外连接。\n",
    "# 3.内连接至显示有共同索引的，outer是全部显示\n",
    "\n",
    "# on=用来指定连接轴,当两张表中的连接轴列名不同时,通过left_on, right_on进行连接\n",
    "pd.merge(student, score, on='name', how=right)\n",
    "# pd.merge(student, score, left_on='name',right_on='名字' how=right)\n",
    "pd.merge(student, score, left_on='key', right_index=True)\n",
    "\n",
    "# suffixes=(‘_x’,’_y’) 指的是当左右对象中存在除连接键外的同名列时，结果集中的区分方式，可以各加一个小尾巴。\n",
    "pd.merge(left, right, on='key1', suffixes=('_left', '_right'))\n",
    "\n",
    "\n",
    "\n",
    "# 表连接 join函数\n",
    "# join默认是以索引连接，内连接\n",
    "\n",
    "# 设置外连接\n",
    "left2.join(right2, how='outer')\n",
    "\n",
    "# 指定连接键\n",
    "left1.join(right1, on='key')\n",
    "\n",
    "# 只要right2, another中的索引有一个可以与left的索引匹配，就可以建立连接\n",
    "left2.join([right2, another])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计分析函数\n",
    "\n",
    "# 一般统计特征函数\n",
    "d1.count() #非空元素计算\n",
    "d1.min() #最小值\n",
    "d1.max() #最大值\n",
    "d1.idxmin() #最小值的位置\n",
    "d1.idxmax() #最大值的位置\n",
    "d1.quantile(0.1) #10%分位数\n",
    "d1.sum() #求和\n",
    "d1.mean() #均值\n",
    "d1.median() #中位数\n",
    "d1.mode() #众数\n",
    "d1.var() #方差\n",
    "d1.std() #标准差\n",
    "d1.mad() #平均绝对偏差\n",
    "d1.skew() #偏度\n",
    "d1.kurt() #峰度\n",
    "d1.describe() #一次性输出多个描述性统计指标\n",
    "\n",
    "# 关于相关系数的计算可以调用pearson方法、kendell方法、spearman方法，默认使用pearson方法。计算的是任意两列的相关系数。\n",
    "df.corr()\n",
    "\n",
    "# 如果只想关注某一个变量与其余变量的相关系数的话，可以使用corrwith,如下方只关心x1与其余变量的相关系数:\n",
    "df.corrwith(df['x1'])\n",
    "\n",
    "# 数值型变量间的协方差矩阵\n",
    "df.cov()\n",
    "\n",
    "# 累计统计特征函数\n",
    "# 使用格式\n",
    "pd.rolling_mean(D, k)  #意思是每k个数计算一次均值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数使用:apply, agg,transform\n",
    "\n",
    "# agg()\n",
    "\n",
    "# 1.agg()和apply()区别\n",
    "# agg函数内调用的函数只能对分组进行聚合使用，比如mean,sum。apply的应用更广泛，apply函数可以说是它的泛化，比如你可以用apply实现组内排序，但是#\n",
    "# agg函数并不能。\n",
    " \n",
    "# 2.agg()使用的多种形式\n",
    "grouped_pct.agg(['mean', 'std', peak_to_peak])\n",
    " \n",
    "#给计算结果一个别名\n",
    "grouped_pct.agg([('foo', 'mean'), ('bar', np.std)])  \n",
    " \n",
    "#列表形式\n",
    "functions = ['count', 'mean', 'max']\n",
    "result = grouped['tip_pct', 'total_bill'].agg(functions)\n",
    " \n",
    "#元组形式\n",
    "ftuples = [('Durchschnitt', 'mean'), ('Abweichung', np.var)]\n",
    "grouped['tip_pct', 'total_bill'].agg(ftuples)\n",
    " \n",
    "#字典形式\n",
    "grouped.agg({'tip' : np.max, 'size' : 'sum'})\n",
    " \n",
    "grouped.agg({'tip_pct' : ['min', 'max', 'mean',  'std'], 'size' : 'sum'})  #混合形式\n",
    "\n",
    "\n",
    "# apply()\n",
    "\n",
    "# apply()作用与数据的每一列，或者每一行\n",
    "\n",
    "def stats(x):\n",
    "    return pd.Series([x.count(),x.min(),x.idxmin()],index = ['Count','Min','Whicn_Min'])\n",
    "#将df数据框的每一列应用status函数,默认axis=0\n",
    "df.apply(stats, axis=0)\n",
    "\n",
    "\n",
    "# transform()\n",
    "\n",
    "# 一般函数性质\n",
    "df.transform(lambda x: (x - x.mean()) / x.std())\n",
    "\n",
    "# 特别函数性质\n",
    "# 在groupby之后使用aggregate，transform则不对数据进行聚合，它会在对应行的位置生成聚合函数值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 缺失值处理\n",
    "\n",
    "# 直接删除\n",
    "# 默认对行进行操作,会删除任意含有缺失值的行\n",
    "df.dropna()      \n",
    "\n",
    "# 删除指定行\n",
    "student.drop([1,4,7])\n",
    "\n",
    "# 删除指定列\n",
    "Student.drop(['列1','列2'], axis=1)\n",
    "\n",
    "#只删除全是缺失值的行\n",
    "df.drop(how=all) \n",
    "\n",
    "# 填补法\n",
    "\n",
    "# 1.使用0填充\n",
    "df.fillna(0)\n",
    "\n",
    "# 2.前向填充和后向填充\n",
    "df.fillna(method=ffill)\n",
    "df.fillna(method=bfill)\n",
    "\n",
    "# 3.常量填充, 或者均值填充，中位数填充\n",
    "df.fillna({'列1': 2，'列2': 3})\n",
    "\n",
    "# 插值法\n",
    "# 自定义列向量拉格朗日插值函数\n",
    "\n",
    "#s为列向量，n为被插值的位置，k为取前后的数据个数，默认为5\n",
    "from scipy.interpolate import lagrange #导入拉格朗日插值函数\n",
    "def ployinterp_column(s, n, k=5):\n",
    "    y = s[list(range(n-k, n)) + list(range(n+1, n+1+k))] #取数\n",
    "    y = y[y.notnull()] #剔除空值\n",
    "    return lagrange(y.index, list(y))  #插值并返回插值结果\n",
    " \n",
    "#逐个元素判断是否需要插值\n",
    "for i in data.columns:\n",
    "    for j in range(len(data)):\n",
    "        if (data[i][j]).isnull(): #如果为空即插值。\n",
    "            data[i][j] = ployinterp_column(data[i], j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据规范化\n",
    "\n",
    "#最小-最大规范化，会作用于每一列\n",
    "(data - data.min())/(data.max() - data.min())\n",
    " \n",
    "#零-均值规范化，会作用于每一列\n",
    "(data - data.mean())/data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 连续属性离散化\n",
    "\n",
    "# 将数据分配到一个数据空间中\n",
    "ages = [20, 22, 25, 27, 21, 23, 37, 31, 61, 45, 41, 32]\n",
    "bins = [18, 25, 35, 60, 100]\n",
    "cats = pd.cut(ages, bins)   #由bins可以得到四个空间，然后将ages中每一个数字放入合适的空间中\n",
    " \n",
    "# 获得每个数据的空间名\n",
    "cats.labels\n",
    " \n",
    "# 获得总共划分了多少空间\n",
    "cats.levels\n",
    " \n",
    "# 查看每个空间有多少数据被划分进去\n",
    "pd.value_counts(cats)\n",
    " \n",
    "# 指定每个空间的开闭口的方位\n",
    "pd.cut(ages, [18, 26, 36, 61, 100], right=False)\n",
    " \n",
    "# 为空间命名\n",
    "group_names = ['Youth', 'YoungAdult', 'MiddleAged', 'Senior']\n",
    "pd.cut(ages, bins, labels=group_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 默认qcut()将数据n等分，可以同给给出累计分布值的方式对数据进行划分\n",
    "data = np.random.randn(100)\n",
    " \n",
    "cats = pd.qcut(data, 4) # Cut into quartiles\n",
    "print(pd.value_counts(cats))\n",
    " \n",
    "pd.qcut(data, [0, 0.1, 0.5, 0.9, 1])  #按照累计分布直进行数据切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}